{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "## 梯度提升樹算法 https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "## 梯度提升用法 補充資料: https://sklearn.apachecn.org/docs/master/12.html \n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 178\\n:Number of Attributes: 13 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - Alcohol\\n    - Malic acid\\n    - Ash\\n    - Alcalinity of ash\\n    - Magnesium\\n    - Total phenols\\n    - Flavanoids\\n    - Nonflavanoid phenols\\n    - Proanthocyanins\\n    - Color intensity\\n    - Hue\\n    - OD280/OD315 of diluted wines\\n    - Proline\\n    - class:\\n        - class_0\\n        - class_1\\n        - class_2\\n\\n:Summary Statistics:\\n\\n============================= ==== ===== ======= =====\\n                                Min   Max   Mean     SD\\n============================= ==== ===== ======= =====\\nAlcohol:                      11.0  14.8    13.0   0.8\\nMalic Acid:                   0.74  5.80    2.34  1.12\\nAsh:                          1.36  3.23    2.36  0.27\\nAlcalinity of Ash:            10.6  30.0    19.5   3.3\\nMagnesium:                    70.0 162.0    99.7  14.3\\nTotal Phenols:                0.98  3.88    2.29  0.63\\nFlavanoids:                   0.34  5.08    2.03  1.00\\nNonflavanoid Phenols:         0.13  0.66    0.36  0.12\\nProanthocyanins:              0.41  3.58    1.59  0.57\\nColour Intensity:              1.3  13.0     5.1   2.3\\nHue:                          0.48  1.71    0.96  0.23\\nOD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\nProline:                       278  1680     746   315\\n============================= ==== ===== ======= =====\\n\\n:Missing Attribute Values: None\\n:Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners:\\n\\nForina, M. et al, PARVUS -\\nAn Extendible Package for Data Exploration, Classification and Correlation.\\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n(1) S. Aeberhard, D. Coomans and O. de Vel,\\nComparison of Classifiers in High Dimensional Settings,\\nTech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\\nMathematics and Statistics, James Cook University of North Queensland.\\n(Also submitted to Technometrics).\\n\\nThe data was used with many others for comparing various\\nclassifiers. The classes are separable, though only RDA\\nhas achieved 100% correct classification.\\n(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\\n(All results using the leave-one-out technique)\\n\\n(2) S. Aeberhard, D. Coomans and O. de Vel,\\n\"THE CLASSIFICATION PERFORMANCE OF RDA\"\\nTech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\\nMathematics and Statistics, James Cook University of North Queensland.\\n(Also submitted to Journal of Chemometrics).\\n\\n|details-end|\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.85157320e-03 -6.11544988e-02  1.03579309e+00  2.47034728e-03\n",
      "  9.77929980e-01  2.56964822e-03  1.00538514e+00  2.00069171e+00\n",
      "  8.76379899e-01  2.12887512e-01  2.98206257e-02  1.01516469e+00\n",
      " -8.90582704e-02  1.90344021e+00 -1.29149562e-03  1.00381041e+00\n",
      "  1.00351325e+00  1.01148092e+00 -3.52097118e-04  1.00030087e+00\n",
      " -1.03837343e-03  9.35022660e-01  1.00785831e+00  2.00190476e+00\n",
      "  2.00083148e+00  2.00144442e+00  1.00236765e+00  8.02429601e-01\n",
      "  9.99729945e-01  6.91969307e-03 -1.31029288e-03  1.00630242e+00\n",
      "  1.99778275e+00  4.03546776e-03 -8.87717408e-04  4.90931604e-03\n",
      "  1.85531342e+00  1.94035978e+00  8.56024167e-01  1.96322471e+00\n",
      "  5.40221304e-04  1.00313198e+00  1.00673704e+00  1.11478224e+00\n",
      "  1.35440638e+00]\n",
      "0.14351527250337612\n"
     ]
    }
   ],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state=42)\n",
    "\n",
    "# 建立模型\n",
    "clf = GradientBoostingRegressor(random_state=7)\n",
    "\n",
    "# 先看看使用預設參數得到的結果，約為 8.379 的 MSE\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "# 設定要訓練的超參數組合\n",
    "n_estimators = [100, 200, 300, 400, 500]\n",
    "max_depth = [1, 3, 5, 7, 9]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "## GridSearchCV:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "## scoring選擇 https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "# 開始搜尋最佳參數\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "# 預設會跑 5-fold cross-validadtion，總共 9 種參數組合，總共要 train 27 次模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: -0.063167 using {'max_depth': 7, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.49637208e-05, 2.49637208e-05, 6.08002456e-01, 2.49637208e-05,\n",
       "       9.99998402e-01, 2.49637208e-05, 9.99998402e-01, 1.99997184e+00,\n",
       "       9.99998402e-01, 2.49637208e-05, 2.49637208e-05, 9.99998402e-01,\n",
       "       2.49637208e-05, 1.99997184e+00, 2.49637208e-05, 9.99998402e-01,\n",
       "       9.99998402e-01, 9.99998402e-01, 2.49637208e-05, 9.99998402e-01,\n",
       "       2.49637208e-05, 9.99998402e-01, 9.99998402e-01, 1.99997184e+00,\n",
       "       1.99997184e+00, 1.99997184e+00, 9.99998402e-01, 7.74091164e-01,\n",
       "       9.99998402e-01, 2.49637208e-05, 2.49637208e-05, 9.99998402e-01,\n",
       "       1.99997184e+00, 2.49637208e-05, 2.49637208e-05, 2.49637208e-05,\n",
       "       1.99997184e+00, 1.99997184e+00, 7.74091164e-01, 1.99997184e+00,\n",
       "       2.49637208e-05, 9.99998402e-01, 9.99998402e-01, 1.33200329e+00,\n",
       "       1.27062394e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用最佳參數重新建立模型\n",
    "clf_bestparam = GradientBoostingRegressor(max_depth=grid_result.best_params_['max_depth'],\n",
    "                                           n_estimators=grid_result.best_params_['n_estimators'])\n",
    "\n",
    "# 訓練模型\n",
    "clf_bestparam.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf_bestparam.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19292865389842173\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
