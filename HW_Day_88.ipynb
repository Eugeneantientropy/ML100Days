{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYY/M7N9OVKKpxQ5hpPXG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eugeneantientropy/ML100Days/blob/main/HW_Day_88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "參考範例程式碼Day088_CB_CustomizedCallbacks.ipynb，請嘗試寫一個 callback 用來記錄各類別在訓練過程中，對驗證集的 True Positive 與 True Negative\n",
        "\n",
        "\n",
        "\n",
        "作業請提交Day088_HW.ipynb"
      ],
      "metadata": {
        "id": "Ehjj2jAFnU0r"
      }
    },
    {
      "source": [
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "train, test = keras.datasets.cifar10.load_data()\n",
        "\n",
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y\n",
        "\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# 資料前處理 - X 標準化\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# 資料前處理 -Y 轉成 onehot\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "建立神經網路，並加入 BN layer\n",
        "\"\"\"\n",
        "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "        if i == 0:\n",
        "            x = keras.layers.Dense(units=n_units,\n",
        "                                   activation=\"relu\",\n",
        "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
        "            x = BatchNormalization()(x)\n",
        "        else:\n",
        "            x = keras.layers.Dense(units=n_units,\n",
        "                                   activation=\"relu\",\n",
        "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "\n",
        "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model\n",
        "\n",
        "## 超參數設定\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "MOMENTUM = 0.95\n",
        "\n",
        "class TP_TN_Tracker(Callback):\n",
        "    def __init__(self, x_val, y_val, threshold=0.5):\n",
        "        super(TP_TN_Tracker, self).__init__()\n",
        "        self.x_val = x_val\n",
        "        self.y_val = y_val\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        y_true = self.y_val.argmax(axis=1)\n",
        "        y_pred_proba = self.model.predict(self.x_val, verbose=0)\n",
        "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "        # 計算 weighted F1-score\n",
        "        f1sc_value = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "        logs[\"val_f1sc\"] = f1sc_value\n",
        "\n",
        "        # 計算 confusion matrix 並取得 TP 和 TN\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        for cls_idx in range(cm.shape[0]):\n",
        "            TP = cm[cls_idx, cls_idx]\n",
        "            FN = np.sum(cm[cls_idx, :]) - TP\n",
        "            FP = np.sum(cm[:, cls_idx]) - TP\n",
        "            TN = np.sum(cm) - (TP + FN + FP)\n",
        "\n",
        "            logs[f\"val_tp_class_{cls_idx}\"] = TP\n",
        "            logs[f\"val_tn_class_{cls_idx}\"] = TN\n",
        "            print(f\"Class {cls_idx}: TP={TP}, TN={TN}\")\n",
        "\n",
        "        print(f\"\\nEpoch {epoch + 1} - Weighted F1 Score: {f1sc_value:.4f}\")\n",
        "\n",
        "# 使用範例\n",
        "log_tp_tn = TP_TN_Tracker(x_val=x_test, y_val=y_test, threshold=0.5)\n",
        "\n",
        "model = build_mlp(input_shape=x_train.shape[1:])\n",
        "model.summary()\n",
        "optimizer = keras.optimizers.SGD(learning_rate=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True,\n",
        "          callbacks=[log_tp_tn]\n",
        "         )\n",
        "\n",
        "# 取得 f1sc 紀錄\n",
        "valid_f1sc = model.history.history['val_f1sc']\n",
        "print(f\"Validation F1 Score per epoch: {valid_f1sc}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4-1U_dkRLwXP",
        "outputId": "98fb6424-268d-48fe-de2e-b86b39fb4c3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,573,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,742,474\u001b[0m (6.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,742,474</span> (6.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,740,682\u001b[0m (6.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,740,682</span> (6.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 3072))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1850 - loss: 2.6204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(32, 3072))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: TP=876, TN=3684\n",
            "Class 1: TP=73, TN=8822\n",
            "Class 2: TP=17, TN=8945\n",
            "Class 3: TP=79, TN=8725\n",
            "Class 4: TP=139, TN=8672\n",
            "Class 5: TP=171, TN=8521\n",
            "Class 6: TP=52, TN=8875\n",
            "Class 7: TP=20, TN=8922\n",
            "Class 8: TP=198, TN=7633\n",
            "Class 9: TP=40, TN=8866\n",
            "\n",
            "Epoch 1 - Weighted F1 Score: 0.1253\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 165ms/step - accuracy: 0.1865 - loss: 2.6135 - val_accuracy: 0.1665 - val_loss: 2.1794 - val_f1sc: 0.1253 - val_tp_class_0: 876.0000 - val_tn_class_0: 3684.0000 - val_tp_class_1: 73.0000 - val_tn_class_1: 8822.0000 - val_tp_class_2: 17.0000 - val_tn_class_2: 8945.0000 - val_tp_class_3: 79.0000 - val_tn_class_3: 8725.0000 - val_tp_class_4: 139.0000 - val_tn_class_4: 8672.0000 - val_tp_class_5: 171.0000 - val_tn_class_5: 8521.0000 - val_tp_class_6: 52.0000 - val_tn_class_6: 8875.0000 - val_tp_class_7: 20.0000 - val_tn_class_7: 8922.0000 - val_tp_class_8: 198.0000 - val_tn_class_8: 7633.0000 - val_tp_class_9: 40.0000 - val_tn_class_9: 8866.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.3771 - loss: 1.7866Class 0: TP=564, TN=7722\n",
            "Class 1: TP=195, TN=8731\n",
            "Class 2: TP=51, TN=8929\n",
            "Class 3: TP=247, TN=8059\n",
            "Class 4: TP=513, TN=7651\n",
            "Class 5: TP=248, TN=8467\n",
            "Class 6: TP=132, TN=8847\n",
            "Class 7: TP=184, TN=8659\n",
            "Class 8: TP=690, TN=7204\n",
            "Class 9: TP=180, TN=8735\n",
            "\n",
            "Epoch 2 - Weighted F1 Score: 0.2709\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.3774 - loss: 1.7859 - val_accuracy: 0.3004 - val_loss: 1.9693 - val_f1sc: 0.2709 - val_tp_class_0: 564.0000 - val_tn_class_0: 7722.0000 - val_tp_class_1: 195.0000 - val_tn_class_1: 8731.0000 - val_tp_class_2: 51.0000 - val_tn_class_2: 8929.0000 - val_tp_class_3: 247.0000 - val_tn_class_3: 8059.0000 - val_tp_class_4: 513.0000 - val_tn_class_4: 7651.0000 - val_tp_class_5: 248.0000 - val_tn_class_5: 8467.0000 - val_tp_class_6: 132.0000 - val_tn_class_6: 8847.0000 - val_tp_class_7: 184.0000 - val_tn_class_7: 8659.0000 - val_tp_class_8: 690.0000 - val_tn_class_8: 7204.0000 - val_tp_class_9: 180.0000 - val_tn_class_9: 8735.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.4256 - loss: 1.6401Class 0: TP=452, TN=8467\n",
            "Class 1: TP=393, TN=8597\n",
            "Class 2: TP=53, TN=8934\n",
            "Class 3: TP=245, TN=8368\n",
            "Class 4: TP=532, TN=7634\n",
            "Class 5: TP=290, TN=8480\n",
            "Class 6: TP=315, TN=8564\n",
            "Class 7: TP=392, TN=8462\n",
            "Class 8: TP=737, TN=7631\n",
            "Class 9: TP=338, TN=8610\n",
            "\n",
            "Epoch 3 - Weighted F1 Score: 0.3568\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4258 - loss: 1.6397 - val_accuracy: 0.3747 - val_loss: 1.8157 - val_f1sc: 0.3568 - val_tp_class_0: 452.0000 - val_tn_class_0: 8467.0000 - val_tp_class_1: 393.0000 - val_tn_class_1: 8597.0000 - val_tp_class_2: 53.0000 - val_tn_class_2: 8934.0000 - val_tp_class_3: 245.0000 - val_tn_class_3: 8368.0000 - val_tp_class_4: 532.0000 - val_tn_class_4: 7634.0000 - val_tp_class_5: 290.0000 - val_tn_class_5: 8480.0000 - val_tp_class_6: 315.0000 - val_tn_class_6: 8564.0000 - val_tp_class_7: 392.0000 - val_tn_class_7: 8462.0000 - val_tp_class_8: 737.0000 - val_tn_class_8: 7631.0000 - val_tp_class_9: 338.0000 - val_tn_class_9: 8610.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.4559 - loss: 1.5559Class 0: TP=464, TN=8606\n",
            "Class 1: TP=463, TN=8579\n",
            "Class 2: TP=103, TN=8860\n",
            "Class 3: TP=212, TN=8486\n",
            "Class 4: TP=437, TN=8150\n",
            "Class 5: TP=309, TN=8485\n",
            "Class 6: TP=518, TN=8196\n",
            "Class 7: TP=547, TN=8059\n",
            "Class 8: TP=699, TN=8116\n",
            "Class 9: TP=406, TN=8621\n",
            "\n",
            "Epoch 4 - Weighted F1 Score: 0.4005\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - accuracy: 0.4560 - loss: 1.5558 - val_accuracy: 0.4158 - val_loss: 1.7010 - val_f1sc: 0.4005 - val_tp_class_0: 464.0000 - val_tn_class_0: 8606.0000 - val_tp_class_1: 463.0000 - val_tn_class_1: 8579.0000 - val_tp_class_2: 103.0000 - val_tn_class_2: 8860.0000 - val_tp_class_3: 212.0000 - val_tn_class_3: 8486.0000 - val_tp_class_4: 437.0000 - val_tn_class_4: 8150.0000 - val_tp_class_5: 309.0000 - val_tn_class_5: 8485.0000 - val_tp_class_6: 518.0000 - val_tn_class_6: 8196.0000 - val_tp_class_7: 547.0000 - val_tn_class_7: 8059.0000 - val_tp_class_8: 699.0000 - val_tn_class_8: 8116.0000 - val_tp_class_9: 406.0000 - val_tn_class_9: 8621.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4793 - loss: 1.4984Class 0: TP=413, TN=8731\n",
            "Class 1: TP=484, TN=8638\n",
            "Class 2: TP=166, TN=8778\n",
            "Class 3: TP=244, TN=8460\n",
            "Class 4: TP=471, TN=8083\n",
            "Class 5: TP=326, TN=8498\n",
            "Class 6: TP=581, TN=8068\n",
            "Class 7: TP=540, TN=8216\n",
            "Class 8: TP=666, TN=8268\n",
            "Class 9: TP=461, TN=8612\n",
            "\n",
            "Epoch 5 - Weighted F1 Score: 0.4261\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - accuracy: 0.4793 - loss: 1.4983 - val_accuracy: 0.4352 - val_loss: 1.6280 - val_f1sc: 0.4261 - val_tp_class_0: 413.0000 - val_tn_class_0: 8731.0000 - val_tp_class_1: 484.0000 - val_tn_class_1: 8638.0000 - val_tp_class_2: 166.0000 - val_tn_class_2: 8778.0000 - val_tp_class_3: 244.0000 - val_tn_class_3: 8460.0000 - val_tp_class_4: 471.0000 - val_tn_class_4: 8083.0000 - val_tp_class_5: 326.0000 - val_tn_class_5: 8498.0000 - val_tp_class_6: 581.0000 - val_tn_class_6: 8068.0000 - val_tp_class_7: 540.0000 - val_tn_class_7: 8216.0000 - val_tp_class_8: 666.0000 - val_tn_class_8: 8268.0000 - val_tp_class_9: 461.0000 - val_tn_class_9: 8612.0000\n",
            "Epoch 6/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4953 - loss: 1.4514Class 0: TP=519, TN=8594\n",
            "Class 1: TP=571, TN=8524\n",
            "Class 2: TP=198, TN=8732\n",
            "Class 3: TP=294, TN=8357\n",
            "Class 4: TP=469, TN=8149\n",
            "Class 5: TP=315, TN=8508\n",
            "Class 6: TP=580, TN=8170\n",
            "Class 7: TP=499, TN=8470\n",
            "Class 8: TP=619, TN=8478\n",
            "Class 9: TP=501, TN=8583\n",
            "\n",
            "Epoch 6 - Weighted F1 Score: 0.4498\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - accuracy: 0.4953 - loss: 1.4513 - val_accuracy: 0.4565 - val_loss: 1.5673 - val_f1sc: 0.4498 - val_tp_class_0: 519.0000 - val_tn_class_0: 8594.0000 - val_tp_class_1: 571.0000 - val_tn_class_1: 8524.0000 - val_tp_class_2: 198.0000 - val_tn_class_2: 8732.0000 - val_tp_class_3: 294.0000 - val_tn_class_3: 8357.0000 - val_tp_class_4: 469.0000 - val_tn_class_4: 8149.0000 - val_tp_class_5: 315.0000 - val_tn_class_5: 8508.0000 - val_tp_class_6: 580.0000 - val_tn_class_6: 8170.0000 - val_tp_class_7: 499.0000 - val_tn_class_7: 8470.0000 - val_tp_class_8: 619.0000 - val_tn_class_8: 8478.0000 - val_tp_class_9: 501.0000 - val_tn_class_9: 8583.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5123 - loss: 1.4038Class 0: TP=473, TN=8689\n",
            "Class 1: TP=548, TN=8558\n",
            "Class 2: TP=158, TN=8805\n",
            "Class 3: TP=283, TN=8375\n",
            "Class 4: TP=483, TN=8124\n",
            "Class 5: TP=325, TN=8544\n",
            "Class 6: TP=565, TN=8239\n",
            "Class 7: TP=488, TN=8482\n",
            "Class 8: TP=707, TN=8164\n",
            "Class 9: TP=504, TN=8554\n",
            "\n",
            "Epoch 7 - Weighted F1 Score: 0.4431\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 181ms/step - accuracy: 0.5123 - loss: 1.4039 - val_accuracy: 0.4534 - val_loss: 1.5476 - val_f1sc: 0.4431 - val_tp_class_0: 473.0000 - val_tn_class_0: 8689.0000 - val_tp_class_1: 548.0000 - val_tn_class_1: 8558.0000 - val_tp_class_2: 158.0000 - val_tn_class_2: 8805.0000 - val_tp_class_3: 283.0000 - val_tn_class_3: 8375.0000 - val_tp_class_4: 483.0000 - val_tn_class_4: 8124.0000 - val_tp_class_5: 325.0000 - val_tn_class_5: 8544.0000 - val_tp_class_6: 565.0000 - val_tn_class_6: 8239.0000 - val_tp_class_7: 488.0000 - val_tn_class_7: 8482.0000 - val_tp_class_8: 707.0000 - val_tn_class_8: 8164.0000 - val_tp_class_9: 504.0000 - val_tn_class_9: 8554.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5243 - loss: 1.3698Class 0: TP=440, TN=8712\n",
            "Class 1: TP=585, TN=8518\n",
            "Class 2: TP=202, TN=8727\n",
            "Class 3: TP=324, TN=8254\n",
            "Class 4: TP=518, TN=8036\n",
            "Class 5: TP=339, TN=8412\n",
            "Class 6: TP=519, TN=8395\n",
            "Class 7: TP=483, TN=8550\n",
            "Class 8: TP=656, TN=8404\n",
            "Class 9: TP=507, TN=8565\n",
            "\n",
            "Epoch 8 - Weighted F1 Score: 0.4525\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 0.5243 - loss: 1.3698 - val_accuracy: 0.4573 - val_loss: 1.5200 - val_f1sc: 0.4525 - val_tp_class_0: 440.0000 - val_tn_class_0: 8712.0000 - val_tp_class_1: 585.0000 - val_tn_class_1: 8518.0000 - val_tp_class_2: 202.0000 - val_tn_class_2: 8727.0000 - val_tp_class_3: 324.0000 - val_tn_class_3: 8254.0000 - val_tp_class_4: 518.0000 - val_tn_class_4: 8036.0000 - val_tp_class_5: 339.0000 - val_tn_class_5: 8412.0000 - val_tp_class_6: 519.0000 - val_tn_class_6: 8395.0000 - val_tp_class_7: 483.0000 - val_tn_class_7: 8550.0000 - val_tp_class_8: 656.0000 - val_tn_class_8: 8404.0000 - val_tp_class_9: 507.0000 - val_tn_class_9: 8565.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5347 - loss: 1.3370Class 0: TP=573, TN=8527\n",
            "Class 1: TP=586, TN=8536\n",
            "Class 2: TP=357, TN=8468\n",
            "Class 3: TP=293, TN=8411\n",
            "Class 4: TP=403, TN=8377\n",
            "Class 5: TP=373, TN=8374\n",
            "Class 6: TP=569, TN=8378\n",
            "Class 7: TP=473, TN=8623\n",
            "Class 8: TP=617, TN=8549\n",
            "Class 9: TP=529, TN=8530\n",
            "\n",
            "Epoch 9 - Weighted F1 Score: 0.4749\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - accuracy: 0.5347 - loss: 1.3370 - val_accuracy: 0.4773 - val_loss: 1.4879 - val_f1sc: 0.4749 - val_tp_class_0: 573.0000 - val_tn_class_0: 8527.0000 - val_tp_class_1: 586.0000 - val_tn_class_1: 8536.0000 - val_tp_class_2: 357.0000 - val_tn_class_2: 8468.0000 - val_tp_class_3: 293.0000 - val_tn_class_3: 8411.0000 - val_tp_class_4: 403.0000 - val_tn_class_4: 8377.0000 - val_tp_class_5: 373.0000 - val_tn_class_5: 8374.0000 - val_tp_class_6: 569.0000 - val_tn_class_6: 8378.0000 - val_tp_class_7: 473.0000 - val_tn_class_7: 8623.0000 - val_tp_class_8: 617.0000 - val_tn_class_8: 8549.0000 - val_tp_class_9: 529.0000 - val_tn_class_9: 8530.0000\n",
            "Epoch 10/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5487 - loss: 1.3084Class 0: TP=496, TN=8677\n",
            "Class 1: TP=626, TN=8451\n",
            "Class 2: TP=209, TN=8775\n",
            "Class 3: TP=375, TN=8174\n",
            "Class 4: TP=464, TN=8213\n",
            "Class 5: TP=310, TN=8553\n",
            "Class 6: TP=550, TN=8405\n",
            "Class 7: TP=537, TN=8479\n",
            "Class 8: TP=670, TN=8450\n",
            "Class 9: TP=505, TN=8565\n",
            "\n",
            "Epoch 10 - Weighted F1 Score: 0.4677\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - accuracy: 0.5486 - loss: 1.3084 - val_accuracy: 0.4742 - val_loss: 1.4816 - val_f1sc: 0.4677 - val_tp_class_0: 496.0000 - val_tn_class_0: 8677.0000 - val_tp_class_1: 626.0000 - val_tn_class_1: 8451.0000 - val_tp_class_2: 209.0000 - val_tn_class_2: 8775.0000 - val_tp_class_3: 375.0000 - val_tn_class_3: 8174.0000 - val_tp_class_4: 464.0000 - val_tn_class_4: 8213.0000 - val_tp_class_5: 310.0000 - val_tn_class_5: 8553.0000 - val_tp_class_6: 550.0000 - val_tn_class_6: 8405.0000 - val_tp_class_7: 537.0000 - val_tn_class_7: 8479.0000 - val_tp_class_8: 670.0000 - val_tn_class_8: 8450.0000 - val_tp_class_9: 505.0000 - val_tn_class_9: 8565.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5562 - loss: 1.2806Class 0: TP=547, TN=8570\n",
            "Class 1: TP=578, TN=8608\n",
            "Class 2: TP=290, TN=8605\n",
            "Class 3: TP=294, TN=8409\n",
            "Class 4: TP=440, TN=8345\n",
            "Class 5: TP=382, TN=8353\n",
            "Class 6: TP=561, TN=8421\n",
            "Class 7: TP=536, TN=8496\n",
            "Class 8: TP=647, TN=8541\n",
            "Class 9: TP=552, TN=8479\n",
            "\n",
            "Epoch 11 - Weighted F1 Score: 0.4790\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.5562 - loss: 1.2806 - val_accuracy: 0.4827 - val_loss: 1.4654 - val_f1sc: 0.4790 - val_tp_class_0: 547.0000 - val_tn_class_0: 8570.0000 - val_tp_class_1: 578.0000 - val_tn_class_1: 8608.0000 - val_tp_class_2: 290.0000 - val_tn_class_2: 8605.0000 - val_tp_class_3: 294.0000 - val_tn_class_3: 8409.0000 - val_tp_class_4: 440.0000 - val_tn_class_4: 8345.0000 - val_tp_class_5: 382.0000 - val_tn_class_5: 8353.0000 - val_tp_class_6: 561.0000 - val_tn_class_6: 8421.0000 - val_tp_class_7: 536.0000 - val_tn_class_7: 8496.0000 - val_tp_class_8: 647.0000 - val_tn_class_8: 8541.0000 - val_tp_class_9: 552.0000 - val_tn_class_9: 8479.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5625 - loss: 1.2590Class 0: TP=511, TN=8645\n",
            "Class 1: TP=614, TN=8540\n",
            "Class 2: TP=346, TN=8571\n",
            "Class 3: TP=287, TN=8392\n",
            "Class 4: TP=338, TN=8618\n",
            "Class 5: TP=407, TN=8312\n",
            "Class 6: TP=642, TN=8186\n",
            "Class 7: TP=507, TN=8561\n",
            "Class 8: TP=657, TN=8503\n",
            "Class 9: TP=555, TN=8536\n",
            "\n",
            "Epoch 12 - Weighted F1 Score: 0.4818\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.5625 - loss: 1.2589 - val_accuracy: 0.4864 - val_loss: 1.4640 - val_f1sc: 0.4818 - val_tp_class_0: 511.0000 - val_tn_class_0: 8645.0000 - val_tp_class_1: 614.0000 - val_tn_class_1: 8540.0000 - val_tp_class_2: 346.0000 - val_tn_class_2: 8571.0000 - val_tp_class_3: 287.0000 - val_tn_class_3: 8392.0000 - val_tp_class_4: 338.0000 - val_tn_class_4: 8618.0000 - val_tp_class_5: 407.0000 - val_tn_class_5: 8312.0000 - val_tp_class_6: 642.0000 - val_tn_class_6: 8186.0000 - val_tp_class_7: 507.0000 - val_tn_class_7: 8561.0000 - val_tp_class_8: 657.0000 - val_tn_class_8: 8503.0000 - val_tp_class_9: 555.0000 - val_tn_class_9: 8536.0000\n",
            "Epoch 13/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5770 - loss: 1.2246Class 0: TP=488, TN=8713\n",
            "Class 1: TP=509, TN=8714\n",
            "Class 2: TP=320, TN=8564\n",
            "Class 3: TP=311, TN=8407\n",
            "Class 4: TP=433, TN=8327\n",
            "Class 5: TP=319, TN=8597\n",
            "Class 6: TP=575, TN=8374\n",
            "Class 7: TP=587, TN=8354\n",
            "Class 8: TP=713, TN=8374\n",
            "Class 9: TP=591, TN=8422\n",
            "\n",
            "Epoch 13 - Weighted F1 Score: 0.4793\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - accuracy: 0.5769 - loss: 1.2247 - val_accuracy: 0.4846 - val_loss: 1.4654 - val_f1sc: 0.4793 - val_tp_class_0: 488.0000 - val_tn_class_0: 8713.0000 - val_tp_class_1: 509.0000 - val_tn_class_1: 8714.0000 - val_tp_class_2: 320.0000 - val_tn_class_2: 8564.0000 - val_tp_class_3: 311.0000 - val_tn_class_3: 8407.0000 - val_tp_class_4: 433.0000 - val_tn_class_4: 8327.0000 - val_tp_class_5: 319.0000 - val_tn_class_5: 8597.0000 - val_tp_class_6: 575.0000 - val_tn_class_6: 8374.0000 - val_tp_class_7: 587.0000 - val_tn_class_7: 8354.0000 - val_tp_class_8: 713.0000 - val_tn_class_8: 8374.0000 - val_tp_class_9: 591.0000 - val_tn_class_9: 8422.0000\n",
            "Epoch 14/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5893 - loss: 1.1961Class 0: TP=590, TN=8525\n",
            "Class 1: TP=598, TN=8593\n",
            "Class 2: TP=333, TN=8556\n",
            "Class 3: TP=308, TN=8405\n",
            "Class 4: TP=430, TN=8352\n",
            "Class 5: TP=361, TN=8475\n",
            "Class 6: TP=544, TN=8485\n",
            "Class 7: TP=569, TN=8397\n",
            "Class 8: TP=643, TN=8565\n",
            "Class 9: TP=532, TN=8555\n",
            "\n",
            "Epoch 14 - Weighted F1 Score: 0.4873\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.5893 - loss: 1.1962 - val_accuracy: 0.4908 - val_loss: 1.4440 - val_f1sc: 0.4873 - val_tp_class_0: 590.0000 - val_tn_class_0: 8525.0000 - val_tp_class_1: 598.0000 - val_tn_class_1: 8593.0000 - val_tp_class_2: 333.0000 - val_tn_class_2: 8556.0000 - val_tp_class_3: 308.0000 - val_tn_class_3: 8405.0000 - val_tp_class_4: 430.0000 - val_tn_class_4: 8352.0000 - val_tp_class_5: 361.0000 - val_tn_class_5: 8475.0000 - val_tp_class_6: 544.0000 - val_tn_class_6: 8485.0000 - val_tp_class_7: 569.0000 - val_tn_class_7: 8397.0000 - val_tp_class_8: 643.0000 - val_tn_class_8: 8565.0000 - val_tp_class_9: 532.0000 - val_tn_class_9: 8555.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5926 - loss: 1.1810Class 0: TP=562, TN=8615\n",
            "Class 1: TP=632, TN=8511\n",
            "Class 2: TP=327, TN=8586\n",
            "Class 3: TP=337, TN=8280\n",
            "Class 4: TP=401, TN=8494\n",
            "Class 5: TP=379, TN=8405\n",
            "Class 6: TP=564, TN=8446\n",
            "Class 7: TP=527, TN=8541\n",
            "Class 8: TP=619, TN=8610\n",
            "Class 9: TP=568, TN=8428\n",
            "\n",
            "Epoch 15 - Weighted F1 Score: 0.4891\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.5926 - loss: 1.1809 - val_accuracy: 0.4916 - val_loss: 1.4456 - val_f1sc: 0.4891 - val_tp_class_0: 562.0000 - val_tn_class_0: 8615.0000 - val_tp_class_1: 632.0000 - val_tn_class_1: 8511.0000 - val_tp_class_2: 327.0000 - val_tn_class_2: 8586.0000 - val_tp_class_3: 337.0000 - val_tn_class_3: 8280.0000 - val_tp_class_4: 401.0000 - val_tn_class_4: 8494.0000 - val_tp_class_5: 379.0000 - val_tn_class_5: 8405.0000 - val_tp_class_6: 564.0000 - val_tn_class_6: 8446.0000 - val_tp_class_7: 527.0000 - val_tn_class_7: 8541.0000 - val_tp_class_8: 619.0000 - val_tn_class_8: 8610.0000 - val_tp_class_9: 568.0000 - val_tn_class_9: 8428.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6005 - loss: 1.1615Class 0: TP=552, TN=8619\n",
            "Class 1: TP=611, TN=8593\n",
            "Class 2: TP=436, TN=8293\n",
            "Class 3: TP=320, TN=8379\n",
            "Class 4: TP=377, TN=8518\n",
            "Class 5: TP=354, TN=8499\n",
            "Class 6: TP=558, TN=8467\n",
            "Class 7: TP=508, TN=8619\n",
            "Class 8: TP=622, TN=8639\n",
            "Class 9: TP=612, TN=8324\n",
            "\n",
            "Epoch 16 - Weighted F1 Score: 0.4934\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.6006 - loss: 1.1614 - val_accuracy: 0.4950 - val_loss: 1.4503 - val_f1sc: 0.4934 - val_tp_class_0: 552.0000 - val_tn_class_0: 8619.0000 - val_tp_class_1: 611.0000 - val_tn_class_1: 8593.0000 - val_tp_class_2: 436.0000 - val_tn_class_2: 8293.0000 - val_tp_class_3: 320.0000 - val_tn_class_3: 8379.0000 - val_tp_class_4: 377.0000 - val_tn_class_4: 8518.0000 - val_tp_class_5: 354.0000 - val_tn_class_5: 8499.0000 - val_tp_class_6: 558.0000 - val_tn_class_6: 8467.0000 - val_tp_class_7: 508.0000 - val_tn_class_7: 8619.0000 - val_tp_class_8: 622.0000 - val_tn_class_8: 8639.0000 - val_tp_class_9: 612.0000 - val_tn_class_9: 8324.0000\n",
            "Epoch 17/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6101 - loss: 1.1361Class 0: TP=464, TN=8741\n",
            "Class 1: TP=661, TN=8474\n",
            "Class 2: TP=401, TN=8435\n",
            "Class 3: TP=273, TN=8430\n",
            "Class 4: TP=418, TN=8446\n",
            "Class 5: TP=427, TN=8289\n",
            "Class 6: TP=538, TN=8518\n",
            "Class 7: TP=533, TN=8521\n",
            "Class 8: TP=644, TN=8590\n",
            "Class 9: TP=545, TN=8460\n",
            "\n",
            "Epoch 17 - Weighted F1 Score: 0.4883\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 177ms/step - accuracy: 0.6101 - loss: 1.1360 - val_accuracy: 0.4904 - val_loss: 1.4496 - val_f1sc: 0.4883 - val_tp_class_0: 464.0000 - val_tn_class_0: 8741.0000 - val_tp_class_1: 661.0000 - val_tn_class_1: 8474.0000 - val_tp_class_2: 401.0000 - val_tn_class_2: 8435.0000 - val_tp_class_3: 273.0000 - val_tn_class_3: 8430.0000 - val_tp_class_4: 418.0000 - val_tn_class_4: 8446.0000 - val_tp_class_5: 427.0000 - val_tn_class_5: 8289.0000 - val_tp_class_6: 538.0000 - val_tn_class_6: 8518.0000 - val_tp_class_7: 533.0000 - val_tn_class_7: 8521.0000 - val_tp_class_8: 644.0000 - val_tn_class_8: 8590.0000 - val_tp_class_9: 545.0000 - val_tn_class_9: 8460.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6203 - loss: 1.1118Class 0: TP=523, TN=8690\n",
            "Class 1: TP=602, TN=8575\n",
            "Class 2: TP=390, TN=8497\n",
            "Class 3: TP=274, TN=8470\n",
            "Class 4: TP=435, TN=8400\n",
            "Class 5: TP=414, TN=8410\n",
            "Class 6: TP=556, TN=8481\n",
            "Class 7: TP=518, TN=8568\n",
            "Class 8: TP=655, TN=8549\n",
            "Class 9: TP=600, TN=8327\n",
            "\n",
            "Epoch 18 - Weighted F1 Score: 0.4938\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - accuracy: 0.6203 - loss: 1.1117 - val_accuracy: 0.4967 - val_loss: 1.4361 - val_f1sc: 0.4938 - val_tp_class_0: 523.0000 - val_tn_class_0: 8690.0000 - val_tp_class_1: 602.0000 - val_tn_class_1: 8575.0000 - val_tp_class_2: 390.0000 - val_tn_class_2: 8497.0000 - val_tp_class_3: 274.0000 - val_tn_class_3: 8470.0000 - val_tp_class_4: 435.0000 - val_tn_class_4: 8400.0000 - val_tp_class_5: 414.0000 - val_tn_class_5: 8410.0000 - val_tp_class_6: 556.0000 - val_tn_class_6: 8481.0000 - val_tp_class_7: 518.0000 - val_tn_class_7: 8568.0000 - val_tp_class_8: 655.0000 - val_tn_class_8: 8549.0000 - val_tp_class_9: 600.0000 - val_tn_class_9: 8327.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6324 - loss: 1.0859Class 0: TP=513, TN=8684\n",
            "Class 1: TP=586, TN=8643\n",
            "Class 2: TP=354, TN=8563\n",
            "Class 3: TP=319, TN=8353\n",
            "Class 4: TP=384, TN=8515\n",
            "Class 5: TP=356, TN=8548\n",
            "Class 6: TP=643, TN=8282\n",
            "Class 7: TP=606, TN=8368\n",
            "Class 8: TP=630, TN=8603\n",
            "Class 9: TP=588, TN=8420\n",
            "\n",
            "Epoch 19 - Weighted F1 Score: 0.4939\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.6324 - loss: 1.0859 - val_accuracy: 0.4979 - val_loss: 1.4411 - val_f1sc: 0.4939 - val_tp_class_0: 513.0000 - val_tn_class_0: 8684.0000 - val_tp_class_1: 586.0000 - val_tn_class_1: 8643.0000 - val_tp_class_2: 354.0000 - val_tn_class_2: 8563.0000 - val_tp_class_3: 319.0000 - val_tn_class_3: 8353.0000 - val_tp_class_4: 384.0000 - val_tn_class_4: 8515.0000 - val_tp_class_5: 356.0000 - val_tn_class_5: 8548.0000 - val_tp_class_6: 643.0000 - val_tn_class_6: 8282.0000 - val_tp_class_7: 606.0000 - val_tn_class_7: 8368.0000 - val_tp_class_8: 630.0000 - val_tn_class_8: 8603.0000 - val_tp_class_9: 588.0000 - val_tn_class_9: 8420.0000\n",
            "Epoch 20/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.6424 - loss: 1.0537Class 0: TP=509, TN=8714\n",
            "Class 1: TP=583, TN=8613\n",
            "Class 2: TP=412, TN=8448\n",
            "Class 3: TP=288, TN=8422\n",
            "Class 4: TP=419, TN=8491\n",
            "Class 5: TP=390, TN=8395\n",
            "Class 6: TP=547, TN=8552\n",
            "Class 7: TP=586, TN=8388\n",
            "Class 8: TP=638, TN=8607\n",
            "Class 9: TP=600, TN=8342\n",
            "\n",
            "Epoch 20 - Weighted F1 Score: 0.4954\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 141ms/step - accuracy: 0.6423 - loss: 1.0539 - val_accuracy: 0.4972 - val_loss: 1.4426 - val_f1sc: 0.4954 - val_tp_class_0: 509.0000 - val_tn_class_0: 8714.0000 - val_tp_class_1: 583.0000 - val_tn_class_1: 8613.0000 - val_tp_class_2: 412.0000 - val_tn_class_2: 8448.0000 - val_tp_class_3: 288.0000 - val_tn_class_3: 8422.0000 - val_tp_class_4: 419.0000 - val_tn_class_4: 8491.0000 - val_tp_class_5: 390.0000 - val_tn_class_5: 8395.0000 - val_tp_class_6: 547.0000 - val_tn_class_6: 8552.0000 - val_tp_class_7: 586.0000 - val_tn_class_7: 8388.0000 - val_tp_class_8: 638.0000 - val_tn_class_8: 8607.0000 - val_tp_class_9: 600.0000 - val_tn_class_9: 8342.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6458 - loss: 1.0433Class 0: TP=607, TN=8552\n",
            "Class 1: TP=589, TN=8620\n",
            "Class 2: TP=402, TN=8423\n",
            "Class 3: TP=325, TN=8340\n",
            "Class 4: TP=464, TN=8313\n",
            "Class 5: TP=378, TN=8442\n",
            "Class 6: TP=502, TN=8641\n",
            "Class 7: TP=570, TN=8506\n",
            "Class 8: TP=611, TN=8649\n",
            "Class 9: TP=552, TN=8514\n",
            "\n",
            "Epoch 21 - Weighted F1 Score: 0.5001\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - accuracy: 0.6458 - loss: 1.0434 - val_accuracy: 0.5000 - val_loss: 1.4407 - val_f1sc: 0.5001 - val_tp_class_0: 607.0000 - val_tn_class_0: 8552.0000 - val_tp_class_1: 589.0000 - val_tn_class_1: 8620.0000 - val_tp_class_2: 402.0000 - val_tn_class_2: 8423.0000 - val_tp_class_3: 325.0000 - val_tn_class_3: 8340.0000 - val_tp_class_4: 464.0000 - val_tn_class_4: 8313.0000 - val_tp_class_5: 378.0000 - val_tn_class_5: 8442.0000 - val_tp_class_6: 502.0000 - val_tn_class_6: 8641.0000 - val_tp_class_7: 570.0000 - val_tn_class_7: 8506.0000 - val_tp_class_8: 611.0000 - val_tn_class_8: 8649.0000 - val_tp_class_9: 552.0000 - val_tn_class_9: 8514.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6565 - loss: 1.0187Class 0: TP=627, TN=8502\n",
            "Class 1: TP=650, TN=8493\n",
            "Class 2: TP=375, TN=8599\n",
            "Class 3: TP=306, TN=8415\n",
            "Class 4: TP=418, TN=8527\n",
            "Class 5: TP=419, TN=8376\n",
            "Class 6: TP=572, TN=8521\n",
            "Class 7: TP=541, TN=8522\n",
            "Class 8: TP=615, TN=8623\n",
            "Class 9: TP=551, TN=8496\n",
            "\n",
            "Epoch 22 - Weighted F1 Score: 0.5038\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 142ms/step - accuracy: 0.6564 - loss: 1.0188 - val_accuracy: 0.5074 - val_loss: 1.4395 - val_f1sc: 0.5038 - val_tp_class_0: 627.0000 - val_tn_class_0: 8502.0000 - val_tp_class_1: 650.0000 - val_tn_class_1: 8493.0000 - val_tp_class_2: 375.0000 - val_tn_class_2: 8599.0000 - val_tp_class_3: 306.0000 - val_tn_class_3: 8415.0000 - val_tp_class_4: 418.0000 - val_tn_class_4: 8527.0000 - val_tp_class_5: 419.0000 - val_tn_class_5: 8376.0000 - val_tp_class_6: 572.0000 - val_tn_class_6: 8521.0000 - val_tp_class_7: 541.0000 - val_tn_class_7: 8522.0000 - val_tp_class_8: 615.0000 - val_tn_class_8: 8623.0000 - val_tp_class_9: 551.0000 - val_tn_class_9: 8496.0000\n",
            "Epoch 23/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6654 - loss: 0.9964Class 0: TP=571, TN=8535\n",
            "Class 1: TP=617, TN=8583\n",
            "Class 2: TP=392, TN=8473\n",
            "Class 3: TP=269, TN=8518\n",
            "Class 4: TP=397, TN=8552\n",
            "Class 5: TP=367, TN=8467\n",
            "Class 6: TP=583, TN=8454\n",
            "Class 7: TP=570, TN=8475\n",
            "Class 8: TP=692, TN=8432\n",
            "Class 9: TP=536, TN=8505\n",
            "\n",
            "Epoch 23 - Weighted F1 Score: 0.4932\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.6654 - loss: 0.9965 - val_accuracy: 0.4994 - val_loss: 1.4454 - val_f1sc: 0.4932 - val_tp_class_0: 571.0000 - val_tn_class_0: 8535.0000 - val_tp_class_1: 617.0000 - val_tn_class_1: 8583.0000 - val_tp_class_2: 392.0000 - val_tn_class_2: 8473.0000 - val_tp_class_3: 269.0000 - val_tn_class_3: 8518.0000 - val_tp_class_4: 397.0000 - val_tn_class_4: 8552.0000 - val_tp_class_5: 367.0000 - val_tn_class_5: 8467.0000 - val_tp_class_6: 583.0000 - val_tn_class_6: 8454.0000 - val_tp_class_7: 570.0000 - val_tn_class_7: 8475.0000 - val_tp_class_8: 692.0000 - val_tn_class_8: 8432.0000 - val_tp_class_9: 536.0000 - val_tn_class_9: 8505.0000\n",
            "Epoch 24/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6707 - loss: 0.9775Class 0: TP=529, TN=8658\n",
            "Class 1: TP=598, TN=8622\n",
            "Class 2: TP=327, TN=8645\n",
            "Class 3: TP=311, TN=8334\n",
            "Class 4: TP=490, TN=8338\n",
            "Class 5: TP=383, TN=8421\n",
            "Class 6: TP=547, TN=8527\n",
            "Class 7: TP=591, TN=8406\n",
            "Class 8: TP=682, TN=8471\n",
            "Class 9: TP=521, TN=8557\n",
            "\n",
            "Epoch 24 - Weighted F1 Score: 0.4950\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.6707 - loss: 0.9776 - val_accuracy: 0.4979 - val_loss: 1.4503 - val_f1sc: 0.4950 - val_tp_class_0: 529.0000 - val_tn_class_0: 8658.0000 - val_tp_class_1: 598.0000 - val_tn_class_1: 8622.0000 - val_tp_class_2: 327.0000 - val_tn_class_2: 8645.0000 - val_tp_class_3: 311.0000 - val_tn_class_3: 8334.0000 - val_tp_class_4: 490.0000 - val_tn_class_4: 8338.0000 - val_tp_class_5: 383.0000 - val_tn_class_5: 8421.0000 - val_tp_class_6: 547.0000 - val_tn_class_6: 8527.0000 - val_tp_class_7: 591.0000 - val_tn_class_7: 8406.0000 - val_tp_class_8: 682.0000 - val_tn_class_8: 8471.0000 - val_tp_class_9: 521.0000 - val_tn_class_9: 8557.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6799 - loss: 0.9577Class 0: TP=537, TN=8600\n",
            "Class 1: TP=637, TN=8476\n",
            "Class 2: TP=409, TN=8397\n",
            "Class 3: TP=249, TN=8554\n",
            "Class 4: TP=426, TN=8469\n",
            "Class 5: TP=383, TN=8437\n",
            "Class 6: TP=597, TN=8400\n",
            "Class 7: TP=519, TN=8599\n",
            "Class 8: TP=663, TN=8525\n",
            "Class 9: TP=522, TN=8485\n",
            "\n",
            "Epoch 25 - Weighted F1 Score: 0.4890\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.6799 - loss: 0.9577 - val_accuracy: 0.4942 - val_loss: 1.4533 - val_f1sc: 0.4890 - val_tp_class_0: 537.0000 - val_tn_class_0: 8600.0000 - val_tp_class_1: 637.0000 - val_tn_class_1: 8476.0000 - val_tp_class_2: 409.0000 - val_tn_class_2: 8397.0000 - val_tp_class_3: 249.0000 - val_tn_class_3: 8554.0000 - val_tp_class_4: 426.0000 - val_tn_class_4: 8469.0000 - val_tp_class_5: 383.0000 - val_tn_class_5: 8437.0000 - val_tp_class_6: 597.0000 - val_tn_class_6: 8400.0000 - val_tp_class_7: 519.0000 - val_tn_class_7: 8599.0000 - val_tp_class_8: 663.0000 - val_tn_class_8: 8525.0000 - val_tp_class_9: 522.0000 - val_tn_class_9: 8485.0000\n",
            "Epoch 26/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6904 - loss: 0.9302Class 0: TP=471, TN=8750\n",
            "Class 1: TP=598, TN=8620\n",
            "Class 2: TP=436, TN=8319\n",
            "Class 3: TP=303, TN=8345\n",
            "Class 4: TP=433, TN=8497\n",
            "Class 5: TP=419, TN=8371\n",
            "Class 6: TP=589, TN=8411\n",
            "Class 7: TP=517, TN=8610\n",
            "Class 8: TP=661, TN=8583\n",
            "Class 9: TP=566, TN=8487\n",
            "\n",
            "Epoch 26 - Weighted F1 Score: 0.4994\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.6903 - loss: 0.9304 - val_accuracy: 0.4993 - val_loss: 1.4646 - val_f1sc: 0.4994 - val_tp_class_0: 471.0000 - val_tn_class_0: 8750.0000 - val_tp_class_1: 598.0000 - val_tn_class_1: 8620.0000 - val_tp_class_2: 436.0000 - val_tn_class_2: 8319.0000 - val_tp_class_3: 303.0000 - val_tn_class_3: 8345.0000 - val_tp_class_4: 433.0000 - val_tn_class_4: 8497.0000 - val_tp_class_5: 419.0000 - val_tn_class_5: 8371.0000 - val_tp_class_6: 589.0000 - val_tn_class_6: 8411.0000 - val_tp_class_7: 517.0000 - val_tn_class_7: 8610.0000 - val_tp_class_8: 661.0000 - val_tn_class_8: 8583.0000 - val_tp_class_9: 566.0000 - val_tn_class_9: 8487.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.6955 - loss: 0.9188Class 0: TP=617, TN=8526\n",
            "Class 1: TP=609, TN=8602\n",
            "Class 2: TP=352, TN=8554\n",
            "Class 3: TP=320, TN=8403\n",
            "Class 4: TP=450, TN=8460\n",
            "Class 5: TP=398, TN=8465\n",
            "Class 6: TP=607, TN=8376\n",
            "Class 7: TP=556, TN=8534\n",
            "Class 8: TP=604, TN=8670\n",
            "Class 9: TP=563, TN=8486\n",
            "\n",
            "Epoch 27 - Weighted F1 Score: 0.5047\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 155ms/step - accuracy: 0.6955 - loss: 0.9188 - val_accuracy: 0.5076 - val_loss: 1.4424 - val_f1sc: 0.5047 - val_tp_class_0: 617.0000 - val_tn_class_0: 8526.0000 - val_tp_class_1: 609.0000 - val_tn_class_1: 8602.0000 - val_tp_class_2: 352.0000 - val_tn_class_2: 8554.0000 - val_tp_class_3: 320.0000 - val_tn_class_3: 8403.0000 - val_tp_class_4: 450.0000 - val_tn_class_4: 8460.0000 - val_tp_class_5: 398.0000 - val_tn_class_5: 8465.0000 - val_tp_class_6: 607.0000 - val_tn_class_6: 8376.0000 - val_tp_class_7: 556.0000 - val_tn_class_7: 8534.0000 - val_tp_class_8: 604.0000 - val_tn_class_8: 8670.0000 - val_tp_class_9: 563.0000 - val_tn_class_9: 8486.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7035 - loss: 0.8941Class 0: TP=610, TN=8529\n",
            "Class 1: TP=574, TN=8665\n",
            "Class 2: TP=400, TN=8447\n",
            "Class 3: TP=322, TN=8379\n",
            "Class 4: TP=476, TN=8293\n",
            "Class 5: TP=377, TN=8432\n",
            "Class 6: TP=498, TN=8634\n",
            "Class 7: TP=549, TN=8525\n",
            "Class 8: TP=635, TN=8644\n",
            "Class 9: TP=575, TN=8468\n",
            "\n",
            "Epoch 28 - Weighted F1 Score: 0.5013\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - accuracy: 0.7034 - loss: 0.8942 - val_accuracy: 0.5016 - val_loss: 1.4557 - val_f1sc: 0.5013 - val_tp_class_0: 610.0000 - val_tn_class_0: 8529.0000 - val_tp_class_1: 574.0000 - val_tn_class_1: 8665.0000 - val_tp_class_2: 400.0000 - val_tn_class_2: 8447.0000 - val_tp_class_3: 322.0000 - val_tn_class_3: 8379.0000 - val_tp_class_4: 476.0000 - val_tn_class_4: 8293.0000 - val_tp_class_5: 377.0000 - val_tn_class_5: 8432.0000 - val_tp_class_6: 498.0000 - val_tn_class_6: 8634.0000 - val_tp_class_7: 549.0000 - val_tn_class_7: 8525.0000 - val_tp_class_8: 635.0000 - val_tn_class_8: 8644.0000 - val_tp_class_9: 575.0000 - val_tn_class_9: 8468.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7119 - loss: 0.8735Class 0: TP=493, TN=8718\n",
            "Class 1: TP=599, TN=8629\n",
            "Class 2: TP=371, TN=8526\n",
            "Class 3: TP=342, TN=8325\n",
            "Class 4: TP=440, TN=8473\n",
            "Class 5: TP=388, TN=8411\n",
            "Class 6: TP=528, TN=8569\n",
            "Class 7: TP=655, TN=8179\n",
            "Class 8: TP=663, TN=8580\n",
            "Class 9: TP=525, TN=8594\n",
            "\n",
            "Epoch 29 - Weighted F1 Score: 0.4993\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.7118 - loss: 0.8736 - val_accuracy: 0.5004 - val_loss: 1.4734 - val_f1sc: 0.4993 - val_tp_class_0: 493.0000 - val_tn_class_0: 8718.0000 - val_tp_class_1: 599.0000 - val_tn_class_1: 8629.0000 - val_tp_class_2: 371.0000 - val_tn_class_2: 8526.0000 - val_tp_class_3: 342.0000 - val_tn_class_3: 8325.0000 - val_tp_class_4: 440.0000 - val_tn_class_4: 8473.0000 - val_tp_class_5: 388.0000 - val_tn_class_5: 8411.0000 - val_tp_class_6: 528.0000 - val_tn_class_6: 8569.0000 - val_tp_class_7: 655.0000 - val_tn_class_7: 8179.0000 - val_tp_class_8: 663.0000 - val_tn_class_8: 8580.0000 - val_tp_class_9: 525.0000 - val_tn_class_9: 8594.0000\n",
            "Epoch 30/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7143 - loss: 0.8606Class 0: TP=601, TN=8511\n",
            "Class 1: TP=579, TN=8648\n",
            "Class 2: TP=347, TN=8583\n",
            "Class 3: TP=333, TN=8355\n",
            "Class 4: TP=470, TN=8413\n",
            "Class 5: TP=378, TN=8470\n",
            "Class 6: TP=587, TN=8463\n",
            "Class 7: TP=534, TN=8589\n",
            "Class 8: TP=660, TN=8541\n",
            "Class 9: TP=565, TN=8481\n",
            "\n",
            "Epoch 30 - Weighted F1 Score: 0.5025\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.7144 - loss: 0.8606 - val_accuracy: 0.5054 - val_loss: 1.4644 - val_f1sc: 0.5025 - val_tp_class_0: 601.0000 - val_tn_class_0: 8511.0000 - val_tp_class_1: 579.0000 - val_tn_class_1: 8648.0000 - val_tp_class_2: 347.0000 - val_tn_class_2: 8583.0000 - val_tp_class_3: 333.0000 - val_tn_class_3: 8355.0000 - val_tp_class_4: 470.0000 - val_tn_class_4: 8413.0000 - val_tp_class_5: 378.0000 - val_tn_class_5: 8470.0000 - val_tp_class_6: 587.0000 - val_tn_class_6: 8463.0000 - val_tp_class_7: 534.0000 - val_tn_class_7: 8589.0000 - val_tp_class_8: 660.0000 - val_tn_class_8: 8541.0000 - val_tp_class_9: 565.0000 - val_tn_class_9: 8481.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7272 - loss: 0.8379Class 0: TP=628, TN=8525\n",
            "Class 1: TP=667, TN=8440\n",
            "Class 2: TP=409, TN=8427\n",
            "Class 3: TP=304, TN=8397\n",
            "Class 4: TP=392, TN=8555\n",
            "Class 5: TP=399, TN=8454\n",
            "Class 6: TP=592, TN=8452\n",
            "Class 7: TP=538, TN=8581\n",
            "Class 8: TP=610, TN=8685\n",
            "Class 9: TP=506, TN=8529\n",
            "\n",
            "Epoch 31 - Weighted F1 Score: 0.5014\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - accuracy: 0.7271 - loss: 0.8380 - val_accuracy: 0.5045 - val_loss: 1.4713 - val_f1sc: 0.5014 - val_tp_class_0: 628.0000 - val_tn_class_0: 8525.0000 - val_tp_class_1: 667.0000 - val_tn_class_1: 8440.0000 - val_tp_class_2: 409.0000 - val_tn_class_2: 8427.0000 - val_tp_class_3: 304.0000 - val_tn_class_3: 8397.0000 - val_tp_class_4: 392.0000 - val_tn_class_4: 8555.0000 - val_tp_class_5: 399.0000 - val_tn_class_5: 8454.0000 - val_tp_class_6: 592.0000 - val_tn_class_6: 8452.0000 - val_tp_class_7: 538.0000 - val_tn_class_7: 8581.0000 - val_tp_class_8: 610.0000 - val_tn_class_8: 8685.0000 - val_tp_class_9: 506.0000 - val_tn_class_9: 8529.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7353 - loss: 0.8151Class 0: TP=607, TN=8516\n",
            "Class 1: TP=607, TN=8582\n",
            "Class 2: TP=352, TN=8594\n",
            "Class 3: TP=295, TN=8410\n",
            "Class 4: TP=428, TN=8486\n",
            "Class 5: TP=400, TN=8430\n",
            "Class 6: TP=563, TN=8503\n",
            "Class 7: TP=580, TN=8438\n",
            "Class 8: TP=631, TN=8648\n",
            "Class 9: TP=572, TN=8428\n",
            "\n",
            "Epoch 32 - Weighted F1 Score: 0.4999\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.7352 - loss: 0.8152 - val_accuracy: 0.5035 - val_loss: 1.4774 - val_f1sc: 0.4999 - val_tp_class_0: 607.0000 - val_tn_class_0: 8516.0000 - val_tp_class_1: 607.0000 - val_tn_class_1: 8582.0000 - val_tp_class_2: 352.0000 - val_tn_class_2: 8594.0000 - val_tp_class_3: 295.0000 - val_tn_class_3: 8410.0000 - val_tp_class_4: 428.0000 - val_tn_class_4: 8486.0000 - val_tp_class_5: 400.0000 - val_tn_class_5: 8430.0000 - val_tp_class_6: 563.0000 - val_tn_class_6: 8503.0000 - val_tp_class_7: 580.0000 - val_tn_class_7: 8438.0000 - val_tp_class_8: 631.0000 - val_tn_class_8: 8648.0000 - val_tp_class_9: 572.0000 - val_tn_class_9: 8428.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7453 - loss: 0.7930Class 0: TP=540, TN=8670\n",
            "Class 1: TP=632, TN=8533\n",
            "Class 2: TP=410, TN=8418\n",
            "Class 3: TP=332, TN=8327\n",
            "Class 4: TP=408, TN=8534\n",
            "Class 5: TP=401, TN=8425\n",
            "Class 6: TP=569, TN=8513\n",
            "Class 7: TP=573, TN=8449\n",
            "Class 8: TP=597, TN=8696\n",
            "Class 9: TP=560, TN=8457\n",
            "\n",
            "Epoch 33 - Weighted F1 Score: 0.5018\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.7452 - loss: 0.7932 - val_accuracy: 0.5022 - val_loss: 1.4846 - val_f1sc: 0.5018 - val_tp_class_0: 540.0000 - val_tn_class_0: 8670.0000 - val_tp_class_1: 632.0000 - val_tn_class_1: 8533.0000 - val_tp_class_2: 410.0000 - val_tn_class_2: 8418.0000 - val_tp_class_3: 332.0000 - val_tn_class_3: 8327.0000 - val_tp_class_4: 408.0000 - val_tn_class_4: 8534.0000 - val_tp_class_5: 401.0000 - val_tn_class_5: 8425.0000 - val_tp_class_6: 569.0000 - val_tn_class_6: 8513.0000 - val_tp_class_7: 573.0000 - val_tn_class_7: 8449.0000 - val_tp_class_8: 597.0000 - val_tn_class_8: 8696.0000 - val_tp_class_9: 560.0000 - val_tn_class_9: 8457.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7510 - loss: 0.7740Class 0: TP=469, TN=8752\n",
            "Class 1: TP=574, TN=8633\n",
            "Class 2: TP=397, TN=8486\n",
            "Class 3: TP=295, TN=8370\n",
            "Class 4: TP=460, TN=8370\n",
            "Class 5: TP=404, TN=8441\n",
            "Class 6: TP=550, TN=8518\n",
            "Class 7: TP=585, TN=8398\n",
            "Class 8: TP=656, TN=8559\n",
            "Class 9: TP=575, TN=8438\n",
            "\n",
            "Epoch 34 - Weighted F1 Score: 0.4952\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.7509 - loss: 0.7741 - val_accuracy: 0.4965 - val_loss: 1.4985 - val_f1sc: 0.4952 - val_tp_class_0: 469.0000 - val_tn_class_0: 8752.0000 - val_tp_class_1: 574.0000 - val_tn_class_1: 8633.0000 - val_tp_class_2: 397.0000 - val_tn_class_2: 8486.0000 - val_tp_class_3: 295.0000 - val_tn_class_3: 8370.0000 - val_tp_class_4: 460.0000 - val_tn_class_4: 8370.0000 - val_tp_class_5: 404.0000 - val_tn_class_5: 8441.0000 - val_tp_class_6: 550.0000 - val_tn_class_6: 8518.0000 - val_tp_class_7: 585.0000 - val_tn_class_7: 8398.0000 - val_tp_class_8: 656.0000 - val_tn_class_8: 8559.0000 - val_tp_class_9: 575.0000 - val_tn_class_9: 8438.0000\n",
            "Epoch 35/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7615 - loss: 0.7506Class 0: TP=517, TN=8647\n",
            "Class 1: TP=533, TN=8684\n",
            "Class 2: TP=466, TN=8233\n",
            "Class 3: TP=290, TN=8405\n",
            "Class 4: TP=433, TN=8451\n",
            "Class 5: TP=368, TN=8493\n",
            "Class 6: TP=571, TN=8494\n",
            "Class 7: TP=575, TN=8487\n",
            "Class 8: TP=660, TN=8549\n",
            "Class 9: TP=538, TN=8508\n",
            "\n",
            "Epoch 35 - Weighted F1 Score: 0.4940\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.7613 - loss: 0.7508 - val_accuracy: 0.4951 - val_loss: 1.5053 - val_f1sc: 0.4940 - val_tp_class_0: 517.0000 - val_tn_class_0: 8647.0000 - val_tp_class_1: 533.0000 - val_tn_class_1: 8684.0000 - val_tp_class_2: 466.0000 - val_tn_class_2: 8233.0000 - val_tp_class_3: 290.0000 - val_tn_class_3: 8405.0000 - val_tp_class_4: 433.0000 - val_tn_class_4: 8451.0000 - val_tp_class_5: 368.0000 - val_tn_class_5: 8493.0000 - val_tp_class_6: 571.0000 - val_tn_class_6: 8494.0000 - val_tp_class_7: 575.0000 - val_tn_class_7: 8487.0000 - val_tp_class_8: 660.0000 - val_tn_class_8: 8549.0000 - val_tp_class_9: 538.0000 - val_tn_class_9: 8508.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7656 - loss: 0.7340Class 0: TP=521, TN=8643\n",
            "Class 1: TP=601, TN=8590\n",
            "Class 2: TP=382, TN=8460\n",
            "Class 3: TP=268, TN=8474\n",
            "Class 4: TP=432, TN=8464\n",
            "Class 5: TP=414, TN=8442\n",
            "Class 6: TP=553, TN=8514\n",
            "Class 7: TP=604, TN=8366\n",
            "Class 8: TP=668, TN=8553\n",
            "Class 9: TP=555, TN=8492\n",
            "\n",
            "Epoch 36 - Weighted F1 Score: 0.4960\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7655 - loss: 0.7342 - val_accuracy: 0.4998 - val_loss: 1.5077 - val_f1sc: 0.4960 - val_tp_class_0: 521.0000 - val_tn_class_0: 8643.0000 - val_tp_class_1: 601.0000 - val_tn_class_1: 8590.0000 - val_tp_class_2: 382.0000 - val_tn_class_2: 8460.0000 - val_tp_class_3: 268.0000 - val_tn_class_3: 8474.0000 - val_tp_class_4: 432.0000 - val_tn_class_4: 8464.0000 - val_tp_class_5: 414.0000 - val_tn_class_5: 8442.0000 - val_tp_class_6: 553.0000 - val_tn_class_6: 8514.0000 - val_tp_class_7: 604.0000 - val_tn_class_7: 8366.0000 - val_tp_class_8: 668.0000 - val_tn_class_8: 8553.0000 - val_tp_class_9: 555.0000 - val_tn_class_9: 8492.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7763 - loss: 0.7139Class 0: TP=531, TN=8652\n",
            "Class 1: TP=620, TN=8564\n",
            "Class 2: TP=457, TN=8253\n",
            "Class 3: TP=334, TN=8267\n",
            "Class 4: TP=403, TN=8507\n",
            "Class 5: TP=427, TN=8316\n",
            "Class 6: TP=560, TN=8498\n",
            "Class 7: TP=510, TN=8641\n",
            "Class 8: TP=607, TN=8671\n",
            "Class 9: TP=511, TN=8591\n",
            "\n",
            "Epoch 37 - Weighted F1 Score: 0.4984\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.7762 - loss: 0.7141 - val_accuracy: 0.4960 - val_loss: 1.5226 - val_f1sc: 0.4984 - val_tp_class_0: 531.0000 - val_tn_class_0: 8652.0000 - val_tp_class_1: 620.0000 - val_tn_class_1: 8564.0000 - val_tp_class_2: 457.0000 - val_tn_class_2: 8253.0000 - val_tp_class_3: 334.0000 - val_tn_class_3: 8267.0000 - val_tp_class_4: 403.0000 - val_tn_class_4: 8507.0000 - val_tp_class_5: 427.0000 - val_tn_class_5: 8316.0000 - val_tp_class_6: 560.0000 - val_tn_class_6: 8498.0000 - val_tp_class_7: 510.0000 - val_tn_class_7: 8641.0000 - val_tp_class_8: 607.0000 - val_tn_class_8: 8671.0000 - val_tp_class_9: 511.0000 - val_tn_class_9: 8591.0000\n",
            "Epoch 38/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7803 - loss: 0.7005Class 0: TP=472, TN=8695\n",
            "Class 1: TP=631, TN=8530\n",
            "Class 2: TP=372, TN=8527\n",
            "Class 3: TP=317, TN=8373\n",
            "Class 4: TP=408, TN=8540\n",
            "Class 5: TP=395, TN=8469\n",
            "Class 6: TP=651, TN=8219\n",
            "Class 7: TP=535, TN=8592\n",
            "Class 8: TP=673, TN=8483\n",
            "Class 9: TP=512, TN=8538\n",
            "\n",
            "Epoch 38 - Weighted F1 Score: 0.4928\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.7803 - loss: 0.7007 - val_accuracy: 0.4966 - val_loss: 1.5411 - val_f1sc: 0.4928 - val_tp_class_0: 472.0000 - val_tn_class_0: 8695.0000 - val_tp_class_1: 631.0000 - val_tn_class_1: 8530.0000 - val_tp_class_2: 372.0000 - val_tn_class_2: 8527.0000 - val_tp_class_3: 317.0000 - val_tn_class_3: 8373.0000 - val_tp_class_4: 408.0000 - val_tn_class_4: 8540.0000 - val_tp_class_5: 395.0000 - val_tn_class_5: 8469.0000 - val_tp_class_6: 651.0000 - val_tn_class_6: 8219.0000 - val_tp_class_7: 535.0000 - val_tn_class_7: 8592.0000 - val_tp_class_8: 673.0000 - val_tn_class_8: 8483.0000 - val_tp_class_9: 512.0000 - val_tn_class_9: 8538.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7851 - loss: 0.6871Class 0: TP=614, TN=8554\n",
            "Class 1: TP=535, TN=8666\n",
            "Class 2: TP=370, TN=8561\n",
            "Class 3: TP=323, TN=8324\n",
            "Class 4: TP=382, TN=8620\n",
            "Class 5: TP=392, TN=8409\n",
            "Class 6: TP=604, TN=8372\n",
            "Class 7: TP=574, TN=8467\n",
            "Class 8: TP=548, TN=8730\n",
            "Class 9: TP=624, TN=8263\n",
            "\n",
            "Epoch 39 - Weighted F1 Score: 0.4947\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.7851 - loss: 0.6872 - val_accuracy: 0.4966 - val_loss: 1.5651 - val_f1sc: 0.4947 - val_tp_class_0: 614.0000 - val_tn_class_0: 8554.0000 - val_tp_class_1: 535.0000 - val_tn_class_1: 8666.0000 - val_tp_class_2: 370.0000 - val_tn_class_2: 8561.0000 - val_tp_class_3: 323.0000 - val_tn_class_3: 8324.0000 - val_tp_class_4: 382.0000 - val_tn_class_4: 8620.0000 - val_tp_class_5: 392.0000 - val_tn_class_5: 8409.0000 - val_tp_class_6: 604.0000 - val_tn_class_6: 8372.0000 - val_tp_class_7: 574.0000 - val_tn_class_7: 8467.0000 - val_tp_class_8: 548.0000 - val_tn_class_8: 8730.0000 - val_tp_class_9: 624.0000 - val_tn_class_9: 8263.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7938 - loss: 0.6642Class 0: TP=525, TN=8671\n",
            "Class 1: TP=619, TN=8556\n",
            "Class 2: TP=472, TN=8259\n",
            "Class 3: TP=326, TN=8299\n",
            "Class 4: TP=388, TN=8575\n",
            "Class 5: TP=440, TN=8291\n",
            "Class 6: TP=532, TN=8592\n",
            "Class 7: TP=530, TN=8604\n",
            "Class 8: TP=591, TN=8702\n",
            "Class 9: TP=571, TN=8445\n",
            "\n",
            "Epoch 40 - Weighted F1 Score: 0.5014\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.7938 - loss: 0.6644 - val_accuracy: 0.4994 - val_loss: 1.5557 - val_f1sc: 0.5014 - val_tp_class_0: 525.0000 - val_tn_class_0: 8671.0000 - val_tp_class_1: 619.0000 - val_tn_class_1: 8556.0000 - val_tp_class_2: 472.0000 - val_tn_class_2: 8259.0000 - val_tp_class_3: 326.0000 - val_tn_class_3: 8299.0000 - val_tp_class_4: 388.0000 - val_tn_class_4: 8575.0000 - val_tp_class_5: 440.0000 - val_tn_class_5: 8291.0000 - val_tp_class_6: 532.0000 - val_tn_class_6: 8592.0000 - val_tp_class_7: 530.0000 - val_tn_class_7: 8604.0000 - val_tp_class_8: 591.0000 - val_tn_class_8: 8702.0000 - val_tp_class_9: 571.0000 - val_tn_class_9: 8445.0000\n",
            "Epoch 41/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8044 - loss: 0.6410Class 0: TP=617, TN=8483\n",
            "Class 1: TP=571, TN=8672\n",
            "Class 2: TP=356, TN=8551\n",
            "Class 3: TP=352, TN=8308\n",
            "Class 4: TP=478, TN=8343\n",
            "Class 5: TP=383, TN=8500\n",
            "Class 6: TP=521, TN=8610\n",
            "Class 7: TP=585, TN=8388\n",
            "Class 8: TP=625, TN=8637\n",
            "Class 9: TP=527, TN=8523\n",
            "\n",
            "Epoch 41 - Weighted F1 Score: 0.5006\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.8043 - loss: 0.6412 - val_accuracy: 0.5015 - val_loss: 1.5519 - val_f1sc: 0.5006 - val_tp_class_0: 617.0000 - val_tn_class_0: 8483.0000 - val_tp_class_1: 571.0000 - val_tn_class_1: 8672.0000 - val_tp_class_2: 356.0000 - val_tn_class_2: 8551.0000 - val_tp_class_3: 352.0000 - val_tn_class_3: 8308.0000 - val_tp_class_4: 478.0000 - val_tn_class_4: 8343.0000 - val_tp_class_5: 383.0000 - val_tn_class_5: 8500.0000 - val_tp_class_6: 521.0000 - val_tn_class_6: 8610.0000 - val_tp_class_7: 585.0000 - val_tn_class_7: 8388.0000 - val_tp_class_8: 625.0000 - val_tn_class_8: 8637.0000 - val_tp_class_9: 527.0000 - val_tn_class_9: 8523.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8080 - loss: 0.6302Class 0: TP=577, TN=8582\n",
            "Class 1: TP=586, TN=8618\n",
            "Class 2: TP=399, TN=8502\n",
            "Class 3: TP=314, TN=8335\n",
            "Class 4: TP=456, TN=8482\n",
            "Class 5: TP=418, TN=8418\n",
            "Class 6: TP=604, TN=8380\n",
            "Class 7: TP=519, TN=8580\n",
            "Class 8: TP=634, TN=8652\n",
            "Class 9: TP=540, TN=8498\n",
            "\n",
            "Epoch 42 - Weighted F1 Score: 0.5039\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.8079 - loss: 0.6302 - val_accuracy: 0.5047 - val_loss: 1.5508 - val_f1sc: 0.5039 - val_tp_class_0: 577.0000 - val_tn_class_0: 8582.0000 - val_tp_class_1: 586.0000 - val_tn_class_1: 8618.0000 - val_tp_class_2: 399.0000 - val_tn_class_2: 8502.0000 - val_tp_class_3: 314.0000 - val_tn_class_3: 8335.0000 - val_tp_class_4: 456.0000 - val_tn_class_4: 8482.0000 - val_tp_class_5: 418.0000 - val_tn_class_5: 8418.0000 - val_tp_class_6: 604.0000 - val_tn_class_6: 8380.0000 - val_tp_class_7: 519.0000 - val_tn_class_7: 8580.0000 - val_tp_class_8: 634.0000 - val_tn_class_8: 8652.0000 - val_tp_class_9: 540.0000 - val_tn_class_9: 8498.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8191 - loss: 0.6061Class 0: TP=523, TN=8579\n",
            "Class 1: TP=553, TN=8644\n",
            "Class 2: TP=368, TN=8487\n",
            "Class 3: TP=318, TN=8364\n",
            "Class 4: TP=485, TN=8346\n",
            "Class 5: TP=347, TN=8570\n",
            "Class 6: TP=527, TN=8568\n",
            "Class 7: TP=563, TN=8470\n",
            "Class 8: TP=688, TN=8466\n",
            "Class 9: TP=563, TN=8441\n",
            "\n",
            "Epoch 43 - Weighted F1 Score: 0.4904\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 158ms/step - accuracy: 0.8190 - loss: 0.6063 - val_accuracy: 0.4935 - val_loss: 1.5795 - val_f1sc: 0.4904 - val_tp_class_0: 523.0000 - val_tn_class_0: 8579.0000 - val_tp_class_1: 553.0000 - val_tn_class_1: 8644.0000 - val_tp_class_2: 368.0000 - val_tn_class_2: 8487.0000 - val_tp_class_3: 318.0000 - val_tn_class_3: 8364.0000 - val_tp_class_4: 485.0000 - val_tn_class_4: 8346.0000 - val_tp_class_5: 347.0000 - val_tn_class_5: 8570.0000 - val_tp_class_6: 527.0000 - val_tn_class_6: 8568.0000 - val_tp_class_7: 563.0000 - val_tn_class_7: 8470.0000 - val_tp_class_8: 688.0000 - val_tn_class_8: 8466.0000 - val_tp_class_9: 563.0000 - val_tn_class_9: 8441.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8232 - loss: 0.5926Class 0: TP=551, TN=8585\n",
            "Class 1: TP=636, TN=8476\n",
            "Class 2: TP=456, TN=8225\n",
            "Class 3: TP=286, TN=8459\n",
            "Class 4: TP=393, TN=8565\n",
            "Class 5: TP=436, TN=8362\n",
            "Class 6: TP=482, TN=8674\n",
            "Class 7: TP=561, TN=8482\n",
            "Class 8: TP=654, TN=8558\n",
            "Class 9: TP=490, TN=8559\n",
            "\n",
            "Epoch 44 - Weighted F1 Score: 0.4926\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - accuracy: 0.8231 - loss: 0.5927 - val_accuracy: 0.4945 - val_loss: 1.5983 - val_f1sc: 0.4926 - val_tp_class_0: 551.0000 - val_tn_class_0: 8585.0000 - val_tp_class_1: 636.0000 - val_tn_class_1: 8476.0000 - val_tp_class_2: 456.0000 - val_tn_class_2: 8225.0000 - val_tp_class_3: 286.0000 - val_tn_class_3: 8459.0000 - val_tp_class_4: 393.0000 - val_tn_class_4: 8565.0000 - val_tp_class_5: 436.0000 - val_tn_class_5: 8362.0000 - val_tp_class_6: 482.0000 - val_tn_class_6: 8674.0000 - val_tp_class_7: 561.0000 - val_tn_class_7: 8482.0000 - val_tp_class_8: 654.0000 - val_tn_class_8: 8558.0000 - val_tp_class_9: 490.0000 - val_tn_class_9: 8559.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8310 - loss: 0.5733Class 0: TP=488, TN=8663\n",
            "Class 1: TP=558, TN=8650\n",
            "Class 2: TP=512, TN=7995\n",
            "Class 3: TP=268, TN=8494\n",
            "Class 4: TP=455, TN=8339\n",
            "Class 5: TP=397, TN=8474\n",
            "Class 6: TP=482, TN=8650\n",
            "Class 7: TP=571, TN=8462\n",
            "Class 8: TP=651, TN=8549\n",
            "Class 9: TP=498, TN=8604\n",
            "\n",
            "Epoch 45 - Weighted F1 Score: 0.4885\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - accuracy: 0.8309 - loss: 0.5735 - val_accuracy: 0.4880 - val_loss: 1.6249 - val_f1sc: 0.4885 - val_tp_class_0: 488.0000 - val_tn_class_0: 8663.0000 - val_tp_class_1: 558.0000 - val_tn_class_1: 8650.0000 - val_tp_class_2: 512.0000 - val_tn_class_2: 7995.0000 - val_tp_class_3: 268.0000 - val_tn_class_3: 8494.0000 - val_tp_class_4: 455.0000 - val_tn_class_4: 8339.0000 - val_tp_class_5: 397.0000 - val_tn_class_5: 8474.0000 - val_tp_class_6: 482.0000 - val_tn_class_6: 8650.0000 - val_tp_class_7: 571.0000 - val_tn_class_7: 8462.0000 - val_tp_class_8: 651.0000 - val_tn_class_8: 8549.0000 - val_tp_class_9: 498.0000 - val_tn_class_9: 8604.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8403 - loss: 0.5568Class 0: TP=601, TN=8489\n",
            "Class 1: TP=589, TN=8588\n",
            "Class 2: TP=412, TN=8427\n",
            "Class 3: TP=355, TN=8251\n",
            "Class 4: TP=445, TN=8466\n",
            "Class 5: TP=379, TN=8483\n",
            "Class 6: TP=559, TN=8485\n",
            "Class 7: TP=523, TN=8609\n",
            "Class 8: TP=601, TN=8651\n",
            "Class 9: TP=510, TN=8525\n",
            "\n",
            "Epoch 46 - Weighted F1 Score: 0.4976\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - accuracy: 0.8402 - loss: 0.5569 - val_accuracy: 0.4974 - val_loss: 1.6101 - val_f1sc: 0.4976 - val_tp_class_0: 601.0000 - val_tn_class_0: 8489.0000 - val_tp_class_1: 589.0000 - val_tn_class_1: 8588.0000 - val_tp_class_2: 412.0000 - val_tn_class_2: 8427.0000 - val_tp_class_3: 355.0000 - val_tn_class_3: 8251.0000 - val_tp_class_4: 445.0000 - val_tn_class_4: 8466.0000 - val_tp_class_5: 379.0000 - val_tn_class_5: 8483.0000 - val_tp_class_6: 559.0000 - val_tn_class_6: 8485.0000 - val_tp_class_7: 523.0000 - val_tn_class_7: 8609.0000 - val_tp_class_8: 601.0000 - val_tn_class_8: 8651.0000 - val_tp_class_9: 510.0000 - val_tn_class_9: 8525.0000\n",
            "Epoch 47/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8421 - loss: 0.5407Class 0: TP=534, TN=8641\n",
            "Class 1: TP=601, TN=8535\n",
            "Class 2: TP=387, TN=8478\n",
            "Class 3: TP=381, TN=8046\n",
            "Class 4: TP=379, TN=8620\n",
            "Class 5: TP=409, TN=8393\n",
            "Class 6: TP=535, TN=8547\n",
            "Class 7: TP=524, TN=8599\n",
            "Class 8: TP=614, TN=8657\n",
            "Class 9: TP=570, TN=8418\n",
            "\n",
            "Epoch 47 - Weighted F1 Score: 0.4954\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - accuracy: 0.8421 - loss: 0.5408 - val_accuracy: 0.4934 - val_loss: 1.6376 - val_f1sc: 0.4954 - val_tp_class_0: 534.0000 - val_tn_class_0: 8641.0000 - val_tp_class_1: 601.0000 - val_tn_class_1: 8535.0000 - val_tp_class_2: 387.0000 - val_tn_class_2: 8478.0000 - val_tp_class_3: 381.0000 - val_tn_class_3: 8046.0000 - val_tp_class_4: 379.0000 - val_tn_class_4: 8620.0000 - val_tp_class_5: 409.0000 - val_tn_class_5: 8393.0000 - val_tp_class_6: 535.0000 - val_tn_class_6: 8547.0000 - val_tp_class_7: 524.0000 - val_tn_class_7: 8599.0000 - val_tp_class_8: 614.0000 - val_tn_class_8: 8657.0000 - val_tp_class_9: 570.0000 - val_tn_class_9: 8418.0000\n",
            "Epoch 48/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8521 - loss: 0.5236Class 0: TP=528, TN=8650\n",
            "Class 1: TP=650, TN=8452\n",
            "Class 2: TP=388, TN=8515\n",
            "Class 3: TP=389, TN=8064\n",
            "Class 4: TP=427, TN=8550\n",
            "Class 5: TP=432, TN=8348\n",
            "Class 6: TP=551, TN=8519\n",
            "Class 7: TP=493, TN=8658\n",
            "Class 8: TP=623, TN=8651\n",
            "Class 9: TP=490, TN=8564\n",
            "\n",
            "Epoch 48 - Weighted F1 Score: 0.4993\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.8520 - loss: 0.5238 - val_accuracy: 0.4971 - val_loss: 1.6528 - val_f1sc: 0.4993 - val_tp_class_0: 528.0000 - val_tn_class_0: 8650.0000 - val_tp_class_1: 650.0000 - val_tn_class_1: 8452.0000 - val_tp_class_2: 388.0000 - val_tn_class_2: 8515.0000 - val_tp_class_3: 389.0000 - val_tn_class_3: 8064.0000 - val_tp_class_4: 427.0000 - val_tn_class_4: 8550.0000 - val_tp_class_5: 432.0000 - val_tn_class_5: 8348.0000 - val_tp_class_6: 551.0000 - val_tn_class_6: 8519.0000 - val_tp_class_7: 493.0000 - val_tn_class_7: 8658.0000 - val_tp_class_8: 623.0000 - val_tn_class_8: 8651.0000 - val_tp_class_9: 490.0000 - val_tn_class_9: 8564.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8574 - loss: 0.5086Class 0: TP=610, TN=8524\n",
            "Class 1: TP=588, TN=8602\n",
            "Class 2: TP=376, TN=8500\n",
            "Class 3: TP=281, TN=8387\n",
            "Class 4: TP=422, TN=8535\n",
            "Class 5: TP=444, TN=8298\n",
            "Class 6: TP=524, TN=8583\n",
            "Class 7: TP=560, TN=8478\n",
            "Class 8: TP=616, TN=8643\n",
            "Class 9: TP=569, TN=8440\n",
            "\n",
            "Epoch 49 - Weighted F1 Score: 0.4972\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.8573 - loss: 0.5087 - val_accuracy: 0.4990 - val_loss: 1.6339 - val_f1sc: 0.4972 - val_tp_class_0: 610.0000 - val_tn_class_0: 8524.0000 - val_tp_class_1: 588.0000 - val_tn_class_1: 8602.0000 - val_tp_class_2: 376.0000 - val_tn_class_2: 8500.0000 - val_tp_class_3: 281.0000 - val_tn_class_3: 8387.0000 - val_tp_class_4: 422.0000 - val_tn_class_4: 8535.0000 - val_tp_class_5: 444.0000 - val_tn_class_5: 8298.0000 - val_tp_class_6: 524.0000 - val_tn_class_6: 8583.0000 - val_tp_class_7: 560.0000 - val_tn_class_7: 8478.0000 - val_tp_class_8: 616.0000 - val_tn_class_8: 8643.0000 - val_tp_class_9: 569.0000 - val_tn_class_9: 8440.0000\n",
            "Epoch 50/50\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8636 - loss: 0.4898Class 0: TP=588, TN=8549\n",
            "Class 1: TP=632, TN=8463\n",
            "Class 2: TP=353, TN=8508\n",
            "Class 3: TP=299, TN=8329\n",
            "Class 4: TP=460, TN=8385\n",
            "Class 5: TP=455, TN=8302\n",
            "Class 6: TP=519, TN=8586\n",
            "Class 7: TP=498, TN=8616\n",
            "Class 8: TP=644, TN=8609\n",
            "Class 9: TP=477, TN=8578\n",
            "\n",
            "Epoch 50 - Weighted F1 Score: 0.4913\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 238ms/step - accuracy: 0.8635 - loss: 0.4899 - val_accuracy: 0.4925 - val_loss: 1.6610 - val_f1sc: 0.4913 - val_tp_class_0: 588.0000 - val_tn_class_0: 8549.0000 - val_tp_class_1: 632.0000 - val_tn_class_1: 8463.0000 - val_tp_class_2: 353.0000 - val_tn_class_2: 8508.0000 - val_tp_class_3: 299.0000 - val_tn_class_3: 8329.0000 - val_tp_class_4: 460.0000 - val_tn_class_4: 8385.0000 - val_tp_class_5: 455.0000 - val_tn_class_5: 8302.0000 - val_tp_class_6: 519.0000 - val_tn_class_6: 8586.0000 - val_tp_class_7: 498.0000 - val_tn_class_7: 8616.0000 - val_tp_class_8: 644.0000 - val_tn_class_8: 8609.0000 - val_tp_class_9: 477.0000 - val_tn_class_9: 8578.0000\n",
            "Validation F1 Score per epoch: [0.1252812631039203, 0.27087319666307685, 0.3568209953616344, 0.4005338608127278, 0.42605634370873596, 0.44975992454421504, 0.44309948321503173, 0.45246636102251897, 0.47489134113270676, 0.46772773031175585, 0.4789689316777547, 0.48177922531345746, 0.4792694664804066, 0.48725123434072437, 0.4891460290468978, 0.4934445719046231, 0.48829865625332297, 0.49382909196245056, 0.4938983249900211, 0.49541560788793365, 0.500103419022068, 0.5038425868030421, 0.49320931726145373, 0.4949995958505667, 0.4890179268481397, 0.49936614791253003, 0.5047323197569291, 0.5012943807365755, 0.4993267276751333, 0.5025132057073731, 0.5013604657206494, 0.49985595697911156, 0.5017565921034783, 0.49516497194399733, 0.4939945890179396, 0.49596574135562543, 0.49841005613321804, 0.4927702033875433, 0.4947320281960391, 0.5013884459081918, 0.5005610687590011, 0.5039120860418753, 0.4904129749159832, 0.4926129684313263, 0.4884599979799706, 0.4975729972534551, 0.49543270507464804, 0.4992572986602122, 0.4972464901459718, 0.4913265875509677]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "08djgKYzEyYO",
        "outputId": "7eb06790-e316-4bd7-a1fc-4cb087b449c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loss' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2993d775ea0d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3iuAZR5UHXm9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}